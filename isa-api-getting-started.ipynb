{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISA-API Getting Started Guide\n",
    "\n",
    "This notebook demonstrates the basic usage of the ISA-API for creating, manipulating, and converting ISA metadata.\n",
    "\n",
    "## What is ISA?\n",
    "\n",
    "The ISA (Investigation-Study-Assay) framework helps manage metadata for life science, environmental, and biomedical experiments. The ISA-API provides tools to:\n",
    "\n",
    "- **Create** ISA objects programmatically\n",
    "- **Validate** ISA datasets\n",
    "- **Convert** between ISA-Tab, ISA-JSON, and other formats\n",
    "- **Read and manipulate** existing ISA datasets\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install isatools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a Simple ISA Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created investigation: My First ISA Investigation\n"
     ]
    }
   ],
   "source": [
    "from isatools.model import (\n",
    "    Investigation,\n",
    "    Study,\n",
    "    Assay,\n",
    "    Source,\n",
    "    Sample,\n",
    "    Material,\n",
    "    Process,\n",
    "    Protocol,\n",
    "    DataFile,\n",
    "    OntologyAnnotation,\n",
    "    OntologySource,\n",
    "    Person,\n",
    "    Publication,\n",
    "    Characteristic,\n",
    "    batch_create_materials\n",
    ")\n",
    "\n",
    "# Create an Investigation\n",
    "investigation = Investigation()\n",
    "investigation.identifier = \"INV001\"\n",
    "investigation.title = \"My First ISA Investigation\"\n",
    "investigation.description = \"A simple example investigation using ISA-API\"\n",
    "investigation.submission_date = \"2025-10-01\"\n",
    "investigation.public_release_date = \"2025-12-01\"\n",
    "\n",
    "print(f\"Created investigation: {investigation.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adding Ontology Sources\n",
    "\n",
    "Ontologies provide controlled vocabularies for describing experimental metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 ontology sources\n"
     ]
    }
   ],
   "source": [
    "# Define ontology sources\n",
    "ncbitaxon = OntologySource(\n",
    "    name='NCBITaxon',\n",
    "    description=\"NCBI Taxonomy\",\n",
    "    file=\"http://purl.bioontology.org/ontology/NCBITAXON\"\n",
    ")\n",
    "\n",
    "obi = OntologySource(\n",
    "    name='OBI',\n",
    "    description=\"Ontology for Biomedical Investigations\",\n",
    "    file=\"http://purl.obolibrary.org/obo/obi.owl\"\n",
    ")\n",
    "\n",
    "# Add to investigation\n",
    "investigation.ontology_source_references.extend([ncbitaxon, obi])\n",
    "\n",
    "print(f\"Added {len(investigation.ontology_source_references)} ontology sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a Study with Contacts and Publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created study: Metabolomics Study of Plant Stress Response\n",
      "  Contact: Jane Scientist\n",
      "  Publication: Plant Stress Response Study\n"
     ]
    }
   ],
   "source": [
    "# Create a study\n",
    "study = Study(filename=\"s_study.txt\")\n",
    "study.identifier = \"STUDY001\"\n",
    "study.title = \"Metabolomics Study of Plant Stress Response\"\n",
    "study.description = \"Investigating metabolic changes in plants under drought stress\"\n",
    "study.submission_date = \"2025-10-01\"\n",
    "study.public_release_date = \"2025-12-01\"\n",
    "\n",
    "# Add study design descriptor\n",
    "intervention_design = OntologyAnnotation(\n",
    "    term=\"intervention design\",\n",
    "    term_accession=\"http://purl.obolibrary.org/obo/OBI_0000115\",\n",
    "    term_source=obi\n",
    ")\n",
    "study.design_descriptors.append(intervention_design)\n",
    "\n",
    "# Add contact person\n",
    "contact = Person(\n",
    "    first_name=\"Jane\",\n",
    "    last_name=\"Scientist\",\n",
    "    affiliation=\"Research Institute\",\n",
    "    email=\"jane.scientist@example.com\",\n",
    "    roles=[OntologyAnnotation(term=\"principal investigator\")]\n",
    ")\n",
    "study.contacts.append(contact)\n",
    "\n",
    "# Add publication\n",
    "publication = Publication(\n",
    "    title=\"Plant Stress Response Study\",\n",
    "    author_list=\"Scientist J, Researcher A\",\n",
    "    pubmed_id=\"12345678\",\n",
    "    doi=\"10.1234/example.doi\"\n",
    ")\n",
    "publication.status = OntologyAnnotation(term=\"published\")\n",
    "study.publications.append(publication)\n",
    "\n",
    "# Add study to investigation\n",
    "investigation.studies.append(study)\n",
    "\n",
    "print(f\"Created study: {study.title}\")\n",
    "print(f\"  Contact: {contact.first_name} {contact.last_name}\")\n",
    "print(f\"  Publication: {publication.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Source Materials and Samples\n",
    "\n",
    "Source materials represent the biological material before any processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 samples:\n",
      "  - control_sample_1\n",
      "  - control_sample_2\n",
      "  - control_sample_3\n",
      "  - treated_sample_1\n",
      "  - treated_sample_2\n",
      "  - treated_sample_3\n"
     ]
    }
   ],
   "source": [
    "# Create a source material\n",
    "source = Source(name='plant_source')\n",
    "\n",
    "# Add organism characteristic\n",
    "organism_characteristic = Characteristic(\n",
    "    category=OntologyAnnotation(term=\"Organism\"),\n",
    "    value=OntologyAnnotation(\n",
    "        term=\"Arabidopsis thaliana\",\n",
    "        term_source=ncbitaxon,\n",
    "        term_accession=\"http://purl.bioontology.org/ontology/NCBITAXON/3702\"\n",
    "    )\n",
    ")\n",
    "source.characteristics.append(organism_characteristic)\n",
    "study.sources.append(source)\n",
    "study.characteristic_categories.append(organism_characteristic.category)\n",
    "\n",
    "# Create sample prototype\n",
    "prototype_sample = Sample(name='sample', derives_from=[source])\n",
    "\n",
    "# Add characteristics to sample\n",
    "treatment_characteristic = Characteristic(\n",
    "    category=OntologyAnnotation(term=\"Treatment\"),\n",
    "    value=OntologyAnnotation(term=\"drought stress\")\n",
    ")\n",
    "prototype_sample.characteristics.append(treatment_characteristic)\n",
    "study.characteristic_categories.append(treatment_characteristic.category)\n",
    "\n",
    "# Create batch of samples (control and treated)\n",
    "study.samples = batch_create_materials(prototype_sample, n=6)\n",
    "\n",
    "# Rename samples for clarity\n",
    "for i, sample in enumerate(study.samples):\n",
    "    if i < 3:\n",
    "        sample.name = f\"control_sample_{i+1}\"\n",
    "    else:\n",
    "        sample.name = f\"treated_sample_{i-2}\"\n",
    "\n",
    "print(f\"Created {len(study.samples)} samples:\")\n",
    "for sample in study.samples:\n",
    "    print(f\"  - {sample.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating Protocols and Processes\n",
    "\n",
    "Protocols describe the experimental procedures, and Processes are instances of protocol execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created protocol: sample collection\n",
      "Process: 1 input -> 6 outputs\n"
     ]
    }
   ],
   "source": [
    "# Create sample collection protocol\n",
    "sample_collection_protocol = Protocol(\n",
    "    name=\"sample collection\",\n",
    "    protocol_type=OntologyAnnotation(term=\"sample collection\")\n",
    ")\n",
    "study.protocols.append(sample_collection_protocol)\n",
    "\n",
    "# Create sample collection process\n",
    "sample_collection_process = Process(executes_protocol=sample_collection_protocol)\n",
    "sample_collection_process.inputs.append(source)\n",
    "sample_collection_process.outputs.extend(study.samples)\n",
    "study.process_sequence.append(sample_collection_process)\n",
    "\n",
    "print(f\"Created protocol: {sample_collection_protocol.name}\")\n",
    "print(f\"Process: {len(sample_collection_process.inputs)} input -> {len(sample_collection_process.outputs)} outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating an Assay with Data Files\n",
    "\n",
    "Assays represent the analytical measurements performed on samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created assay: a_metabolomics.txt\n",
      "  Measurement type: metabolite profiling\n",
      "  Technology type: mass spectrometry\n",
      "  Data files: 6\n"
     ]
    }
   ],
   "source": [
    "# Create an assay\n",
    "assay = Assay(filename=\"a_metabolomics.txt\")\n",
    "assay.measurement_type = OntologyAnnotation(term=\"metabolite profiling\")\n",
    "assay.technology_type = OntologyAnnotation(term=\"mass spectrometry\")\n",
    "\n",
    "# Create extraction protocol\n",
    "extraction_protocol = Protocol(\n",
    "    name='metabolite extraction',\n",
    "    protocol_type=OntologyAnnotation(term=\"extraction\")\n",
    ")\n",
    "study.protocols.append(extraction_protocol)\n",
    "\n",
    "# Create mass spectrometry protocol\n",
    "ms_protocol = Protocol(\n",
    "    name='mass spectrometry',\n",
    "    protocol_type=OntologyAnnotation(term=\"mass spectrometry\")\n",
    ")\n",
    "study.protocols.append(ms_protocol)\n",
    "\n",
    "# Create processes for each sample\n",
    "for i, sample in enumerate(study.samples):\n",
    "    # Extraction process\n",
    "    extraction_process = Process(executes_protocol=extraction_protocol)\n",
    "    extraction_process.inputs.append(sample)\n",
    "    \n",
    "    extract = Material(name=f\"extract_{i}\")\n",
    "    extract.type = \"Extract Name\"\n",
    "    extraction_process.outputs.append(extract)\n",
    "    \n",
    "    # MS analysis process\n",
    "    ms_process = Process(executes_protocol=ms_protocol)\n",
    "    ms_process.inputs.append(extract)\n",
    "    \n",
    "    # Create data file\n",
    "    data_file = DataFile(\n",
    "        filename=f\"ms_data_{sample.name}.mzML\",\n",
    "        label=\"Raw Data File\"\n",
    "    )\n",
    "    ms_process.outputs.append(data_file)\n",
    "    \n",
    "    # Add to assay\n",
    "    assay.samples.append(sample)\n",
    "    assay.other_material.append(extract)\n",
    "    assay.data_files.append(data_file)\n",
    "    assay.process_sequence.append(extraction_process)\n",
    "    assay.process_sequence.append(ms_process)\n",
    "\n",
    "# Add assay to study\n",
    "study.assays.append(assay)\n",
    "\n",
    "print(f\"Created assay: {assay.filename}\")\n",
    "print(f\"  Measurement type: {assay.measurement_type.term}\")\n",
    "print(f\"  Technology type: {assay.technology_type.term}\")\n",
    "print(f\"  Data files: {len(assay.data_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exporting to ISA-JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISA-JSON output (first 1000 characters):\n",
      "{\n",
      "  \"comments\": [],\n",
      "  \"description\": \"A simple example investigation using ISA-API\",\n",
      "  \"identifier\": \"INV001\",\n",
      "  \"ontologySourceReferences\": [\n",
      "    {\n",
      "      \"comments\": [],\n",
      "      \"description\": \"NCBI Taxonomy\",\n",
      "      \"file\": \"http://purl.bioontology.org/ontology/NCBITAXON\",\n",
      "      \"name\": \"NCBITaxon\",\n",
      "      \"version\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"comments\": [],\n",
      "      \"description\": \"Ontology for Biomedical Investigations\",\n",
      "      \"file\": \"http://purl.obolibrary.org/obo/obi.owl\",\n",
      "      \"name\": \"OBI\",\n",
      "      \"version\": \"\"\n",
      "    }\n",
      "  ],\n",
      "  \"people\": [],\n",
      "  \"publicReleaseDate\": \"2025-12-01\",\n",
      "  \"publications\": [],\n",
      "  \"studies\": [\n",
      "    {\n",
      "      \"assays\": [\n",
      "        {\n",
      "          \"characteristicCategories\": [],\n",
      "          \"comments\": [],\n",
      "          \"dataFiles\": [\n",
      "            {\n",
      "              \"@id\": \"#data_file/f9d80419-4738-478d-9fbc-7fa91430e55c\",\n",
      "              \"comments\": [],\n",
      "              \"name\": \"ms_data_control_sample_1.mzML\",\n",
      "              \"type\": \"Raw Data File\"\n",
      "            },\n",
      "            {\n",
      "              \"@id\"\n",
      "\n",
      "... (output truncated)\n",
      "\n",
      "Saved ISA-JSON to: example_isa.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "\n",
    "# Convert to JSON string\n",
    "isa_json = json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=2)\n",
    "\n",
    "# Display first 1000 characters\n",
    "print(\"ISA-JSON output (first 1000 characters):\")\n",
    "print(isa_json[:1000])\n",
    "print(\"\\n... (output truncated)\")\n",
    "\n",
    "# Save to file\n",
    "with open('example_isa.json', 'w') as f:\n",
    "    f.write(isa_json)\n",
    "\n",
    "print(\"\\nSaved ISA-JSON to: example_isa.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exporting to ISA-Tab Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sample Name', 'Protocol REF.0']\n",
      "['Sample Name', 'Protocol REF.0', 'Extract Name', 'Protocol REF.1', 'MS Assay Name.0']\n",
      "Created ISA-Tab files in './isa_tab_output':\n",
      "  - a_metabolomics.txt\n",
      "  - i_investigation.txt\n",
      "  - s_study.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdrwacker/workspace/isa-api/isatools/isatab/dump/write.py:237: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  DF = DF.replace('', nan)\n",
      "/Users/sdrwacker/workspace/isa-api/isatools/isatab/dump/write.py:537: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  DF = DF.replace('', nan)\n"
     ]
    }
   ],
   "source": [
    "from isatools import isatab\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = './isa_tab_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Write ISA-Tab files\n",
    "isatab.dump(investigation, output_dir)\n",
    "\n",
    "# List created files\n",
    "created_files = os.listdir(output_dir)\n",
    "print(f\"Created ISA-Tab files in '{output_dir}':\")\n",
    "for file in sorted(created_files):\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reading Existing ISA-Tab Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded investigation: INV001\n",
      "  Title: My First ISA Investigation\n",
      "  Number of studies: 1\n",
      "\n",
      "  Study: STUDY001\n",
      "    Title: Metabolomics Study of Plant Stress Response\n",
      "    Sources: 1\n",
      "    Samples: 6\n",
      "    Assays: 1\n",
      "      Assay: a_metabolomics.txt\n",
      "        Data files: 6\n"
     ]
    }
   ],
   "source": [
    "# Read back the ISA-Tab we just created\n",
    "with open(os.path.join(output_dir, 'i_investigation.txt')) as f:\n",
    "    loaded_investigation = isatab.load(f)\n",
    "\n",
    "print(f\"Loaded investigation: {loaded_investigation.identifier}\")\n",
    "print(f\"  Title: {loaded_investigation.title}\")\n",
    "print(f\"  Number of studies: {len(loaded_investigation.studies)}\")\n",
    "\n",
    "for study in loaded_investigation.studies:\n",
    "    print(f\"\\n  Study: {study.identifier}\")\n",
    "    print(f\"    Title: {study.title}\")\n",
    "    print(f\"    Sources: {len(study.sources)}\")\n",
    "    print(f\"    Samples: {len(study.samples)}\")\n",
    "    print(f\"    Assays: {len(study.assays)}\")\n",
    "    \n",
    "    for assay in study.assays:\n",
    "        print(f\"      Assay: {assay.filename}\")\n",
    "        print(f\"        Data files: {len(assay.data_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Validating ISA-Tab Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Report:\n",
      "  Errors: 0\n",
      "  Warnings: 1\n",
      "  Info: 2\n",
      "\n",
      "✓ Validation successful! No errors found.\n"
     ]
    }
   ],
   "source": [
    "from isatools import isatab\n",
    "\n",
    "# Validate the ISA-Tab directory\n",
    "try:\n",
    "    validation_report = isatab.validate(open(os.path.join(output_dir, 'i_investigation.txt')))\n",
    "    \n",
    "    print(\"Validation Report:\")\n",
    "    print(f\"  Errors: {len(validation_report.get('errors', []))}\")\n",
    "    print(f\"  Warnings: {len(validation_report.get('warnings', []))}\")\n",
    "    print(f\"  Info: {len(validation_report.get('info', []))}\")\n",
    "    \n",
    "    if validation_report.get('errors'):\n",
    "        print(\"\\nErrors found:\")\n",
    "        for error in validation_report['errors'][:5]:  # Show first 5 errors\n",
    "            print(f\"  - {error}\")\n",
    "    else:\n",
    "        print(\"\\n✓ Validation successful! No errors found.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Converting ISA-Tab to ISA-JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted ISA-Tab to ISA-JSON\n",
      "Output saved to: converted_isa.json\n",
      "JSON size: 26338 characters\n"
     ]
    }
   ],
   "source": [
    "from isatools import isatab\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "\n",
    "# Read ISA-Tab\n",
    "with open(os.path.join(output_dir, 'i_investigation.txt')) as f:\n",
    "    inv = isatab.load(f)\n",
    "\n",
    "# Convert to JSON\n",
    "json_output = json.dumps(inv, cls=ISAJSONEncoder, indent=2)\n",
    "\n",
    "# Save JSON\n",
    "with open('converted_isa.json', 'w') as f:\n",
    "    f.write(json_output)\n",
    "\n",
    "print(\"Converted ISA-Tab to ISA-JSON\")\n",
    "print(f\"Output saved to: converted_isa.json\")\n",
    "print(f\"JSON size: {len(json_output)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✓ Creating ISA Investigation, Study, and Assay objects\n",
    "2. ✓ Adding ontology annotations and controlled vocabularies\n",
    "3. ✓ Creating source materials, samples, and processes\n",
    "4. ✓ Defining protocols and linking them to processes\n",
    "5. ✓ Creating assays with data files\n",
    "6. ✓ Exporting to ISA-JSON format\n",
    "7. ✓ Exporting to ISA-Tab format\n",
    "8. ✓ Reading existing ISA-Tab files\n",
    "9. ✓ Validating ISA metadata\n",
    "10. ✓ Converting between ISA-Tab and ISA-JSON\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- **Documentation**: https://isa-tools.org/isa-api/\n",
    "- **GitHub**: https://github.com/ISA-tools/isa-api\n",
    "- **ISA Community**: https://www.isacommons.org\n",
    "- **ISA Cookbook**: More advanced examples in the `isa-cookbook/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isa-api-py312",
   "language": "python",
   "name": "isa-api-py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
